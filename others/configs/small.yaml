# SCI-ARC Small Model Configuration
# ===========================================================================
# PURPOSE: FAST EXPERIMENTS and debugging
# Use Case: Testing code changes, quick prototyping, CI/CD
# NOT for publication - ~30% lower accuracy expected
#
# Parameters: ~3M
# Training Time: ~2-4 hours
# ===========================================================================

model:
  hidden_dim: 128
  num_colors: 10
  max_grid_size: 30
  
  num_structure_slots: 4
  se_layers: 2                  # Transformer encoder layers
  structure_heads: 4
  use_abstraction: true
  
  max_objects: 8
  content_heads: 4
  
  binding_heads: 4
  
  H_cycles: 2
  L_cycles: 2
  L_layers: 2
  
  dropout: 0.1

training:
  learning_rate: 5.0e-4
  weight_decay: 0.01
  max_epochs: 50
  warmup_epochs: 3
  grad_clip: 1.0
  grad_accumulation_steps: 1
  
  # Batch size optimal for RTX 3090 24GB
  batch_size: 192
  eval_batch_size: 192
  
  scl_weight: 1.0               # SCL weight (BatchNorm fix makes SCL work)
  ortho_weight: 0.01
  deep_supervision_weight: 0.5
  
  # CISL: Content-Invariant Structure Learning (replaces SCL for few-shot)
  # Note: Config params use 'cicl_' prefix for backward compatibility
  use_cicl: true                # Enable CISL instead of legacy SCL
  cicl_consist_weight: 0.5      # Within-task consistency weight (λ₁)
  cicl_color_inv_weight: 0.5    # Content invariance weight (λ₂)
  cicl_variance_weight: 0.1     # Batch variance weight (λ₃, anti-collapse)
  cicl_target_std: 0.5          # Target std (γ) for variance regularization
  
  # Anti-background-collapse (CRITICAL for ARC's ~85% background grids)
  focal_gamma: 2.0              # Focal Loss gamma (down-weights easy/background pixels)
  use_class_weights: true       # Background weight=0.1, others=1.0
  label_smoothing: 0.1          # Prevents overconfident predictions
  
  scheduler_type: cosine
  min_lr: 1.0e-6
  
  use_amp: true
  use_curriculum: false         # Faster training without curriculum

data:
  # Dataset paths
  arc_dir: ./data/arc-agi/data  # Contains training/ and evaluation/ subdirectories
  rearc_dir: null
  
  # Data loading
  num_workers: 24
  pin_memory: true
  
  # Caching - enabled for fast iteration during debugging
  cache_samples: true           # Pre-cache for speed
  cache_augmentations: 8        # 8 versions per task
  
  augment: true
  
  # SCL Transform Family Assignment
  use_augment_family: true      # Use augmentation type as transform_family for SCL

evaluation:
  num_attempts: 2
  use_voting: false
  temperature: 1.0

logging:
  log_every: 20
  eval_every: 2
  save_every: 10
  keep_last_n: 2
  log_to_file: true             # Save all terminal output to log file
  use_wandb: true
  wandb_project: sci-arc-small
  checkpoint_dir: ./checkpoints/small

hardware:
  device: cuda
  seed: 42
