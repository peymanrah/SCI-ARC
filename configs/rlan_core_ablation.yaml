# RLAN Core Ablation Configuration
# ==================================
# Tests the CORE NOVELTY of RLAN: DSC + MSRE (spatial anchoring + relative coords)
# 
# ENABLED MODULES:
#   - ContextEncoder: 4.2M params (REQUIRED - provides task signal)
#   - DSC: 266K params (CORE - find spatial anchors)
#   - MSRE: 109K params (CORE - relative coordinate encoding)
#   - Encoder + Solver: Core pipeline
#
# DISABLED MODULES:
#   - LCR: 403K params → 0 (no soft counting)
#   - SPH: 232K params → 0 (no symbolic predicates)
#
# This tests the hypothesis:
#   "Can RLAN solve tasks by reasoning in relative coordinates 
#    anchored to dynamically discovered features?"
#
# If this config works better than RLAN-Full, it proves the core novelty
# and suggests LCR/SPH are not essential.
#
# ==================================
# DEBUGGING CHECKPOINTS (what to look for in training logs)
# ==================================
# 
# EPOCH 5-10 (Early training):
#   - Grad Norms: DSC should be > 0.01 (gradients flowing)
#   - Per-Clue Entropy: Should be < 5.0 (attention starting to focus)
#   - Attention max: Should be > 0.01 (not uniform)
#   - Task Loss: Should be dropping from ~2.4
#
# EPOCH 25 (DSC should be contributing):
#   - Per-Clue Entropy: Should be < 4.0 (focused attention)
#   - Centroid Spread: Should be > 3.0 (clues spreading out)
#   - Per-Step Loss: Later steps should be lower than earlier steps
#   - Non-BG Accuracy: Should be > 0.1 (not just predicting black)
#
# EPOCH 50 (DSC fully engaged):
#   - Per-Clue Entropy: Should be < 3.0 (sharp attention)
#   - Attention max: Should be > 0.1 (very focused)
#   - Task Accuracy: Should be > 0.0 (some tasks solved)
#   - Deep Supervision Loss: Should be > 0.0 (contributing to learning)
#
# RED FLAGS (problems requiring intervention):
#   - DSC grad norm < 0.001 → gradients not reaching DSC
#   - Entropy > 5.0 after epoch 25 → attention still diffuse
#   - Centroid spread < 2.0 → all clues attending to same location
#   - Non-BG Accuracy decreasing → background collapse
#   - Per-Step Loss not improving → solver not refining
# ==================================

model:
  type: "rlan"
  hidden_dim: 256
  num_colors: 10
  num_classes: 10
  max_grid_size: 30
  
  max_clues: 6
  num_predicates: 8
  num_solver_steps: 6
  
  use_act: true
  dropout: 0.1
  
  dsc_num_heads: 4
  lcr_num_heads: 4
  
  msre_encoding_dim: 32
  msre_num_freq: 8
  lcr_num_freq: 8
  
  # =============================================================
  # ABLATION: Core Novelty Only (DSC + MSRE)
  # =============================================================
  # NOTE: ContextEncoder MUST be enabled - it provides task signal!
  # Without it, the model has NO information about what transformation
  # to learn, causing inevitable background collapse.
  # 
  # The bottleneck concern (4.2M params -> 256-dim) is real but:
  # 1. The context vector conditions DSC's clue discovery
  # 2. Without context, DSC finds random clues
  # 3. Even a compressed signal is better than none
  # =============================================================
  use_context_encoder: true   # ENABLED - REQUIRED for task signal
  use_dsc: true               # ENABLED - CORE NOVELTY
  use_msre: true              # ENABLED - CORE NOVELTY
  use_lcr: false              # DISABLED - auxiliary
  use_sph: false              # DISABLED - auxiliary
  use_learned_pos: false      # Use sinusoidal (default) vs learned absolute positions

training:
  max_epochs: 500
  
  batch_size: 64  # Reduced since ContextEncoder is now enabled
  grad_accumulation_steps: 4
  
  learning_rate: 1.0e-4
  weight_decay: 0.1
  gradient_clip: 1.0
  
  # Temperature schedule for Gumbel-Softmax (DSC attention sharpness)
  # =================================================================
  # GOAL: See DSC contribute meaningfully within first 50 epochs
  # 
  # Temperature controls attention sharpness in Gumbel-Softmax:
  #   temp > 2.0: Nearly uniform attention (99% entropy) - DSC can't learn
  #   temp ~ 1.0: Moderately sharp - DSC starts learning
  #   temp < 0.5: Very sharp - risk of gradient issues
  #
  # Schedule analysis (exponential decay):
  #   tau_start=5.0: reaches 1.0 at epoch 206 (TOO SLOW)
  #   tau_start=2.0: reaches 1.0 at epoch 116 (STILL SLOW)
  #   tau_start=1.0: always below 1.0, sharp from start (FOR DEBUGGING)
  #
  # Using 1.0 for debugging - we need to see DSC working early!
  # =================================================================
  temperature_start: 1.0   # Sharp from start for debugging DSC
  temperature_end: 0.1
  
  # FOCAL_STABLEMAX: Critical for anti-background-collapse
  # ARC grids are ~85% background, so pure CE leads to predicting all-background.
  # Focal loss down-weights easy (background) predictions, alpha weights foreground more.
  loss_mode: 'focal_stablemax'
  
  # focal_gamma=2.0: Hard examples (low confidence) get 25x more weight than easy ones
  # focal_alpha=0.75: Foreground pixels get 3x more weight than background
  focal_gamma: 2.0
  focal_alpha: 0.75  # HIGH alpha = MORE weight on foreground (was 0.25, which inverted!)
  
  # Auxiliary loss weights
  # =================================================================
  # lambda_entropy: Penalizes high entropy (diffuse attention)
  #   - Higher = stronger pressure for sharp attention
  #   - 0.1 is mild, 0.5 is strong
  #   - Increase if DSC entropy stays high (>4.0) after epoch 25
  #
  # CRITICAL: Higher entropy penalty forces DSC to focus on fewer pixels,
  # which naturally leads to focusing on foreground objects (sparse in ARC)
  #
  # lambda_sparsity: Now a MINIMUM CLUE USAGE penalty (not sparsity!)
  # Encourages using at least 2-3 clues for meaningful spatial reasoning.
  # Without this, the model tends to stop immediately (DSC Clues Used → 0.17)
  # =================================================================
  lambda_entropy: 0.5      # Strong pressure - force sharp attention on sparse foreground
  lambda_sparsity: 0.3     # ENABLED - minimum clue usage penalty
  min_clues: 1.0           # Minimum 1 clue (some ARC tasks need only 1, model learns to grow)
  lambda_predicate: 0.0    # Disabled - no SPH in this ablation
  lambda_curriculum: 0.0
  lambda_deep_supervision: 0.5  # Stronger intermediate supervision
  lambda_act: 0.1          # ACT halting loss (teaches when to stop refining)
  
  use_stablemax: true
  
  use_curriculum: false
  curriculum_stages: []
  
  optimizer: "adamw"
  beta1: 0.9
  beta2: 0.95
  scheduler: "onecycle"
  warmup_epochs: 20
  min_lr: 1.0e-6
  
  use_ema: true
  ema_decay: 0.999

data:
  train_path: "./data/arc-agi/data/training"
  eval_path: "./data/arc-agi/data/evaluation"
  
  max_grid_size: 30
  
  num_workers: 24
  pin_memory: true
  prefetch_factor: 4
  persistent_workers: true
  
  cache_samples: false
  
  augmentation:
    enabled: true
    rotation: true
    flip: true
    transpose: true
    color_permutation: true
    translational: true

evaluation:
  num_guesses: 2
  use_tta: true
  tta_rotations: [0, 90, 180, 270]
  tta_flips: [false, true]

logging:
  log_every: 1
  save_every: 25
  eval_every: 5
  keep_last_n: 5
  checkpoint_dir: "checkpoints/rlan_core_ablation"
  log_to_file: true
  track_augmentation: true
  
  use_wandb: false
  wandb_project: "rlan-arc"
  wandb_run_name: null

hardware:
  device: "cuda"
  seed: 42
  deterministic: false

device:
  use_cuda: true
  mixed_precision: true
  dtype: "bfloat16"
  compile: false
