# RLAN Core Ablation Configuration
# ==================================
# Tests the CORE NOVELTY of RLAN: DSC + MSRE (spatial anchoring + relative coords)
# 
# ENABLED MODULES:
#   - ContextEncoder: 4.2M params (REQUIRED - provides task signal)
#   - DSC: 266K params (CORE - find spatial anchors)
#   - MSRE: 109K params (CORE - relative coordinate encoding)
#   - Encoder + Solver: Core pipeline
#
# DISABLED MODULES:
#   - LCR: 403K params → 0 (no soft counting)
#   - SPH: 232K params → 0 (no symbolic predicates)
#
# This tests the hypothesis:
#   "Can RLAN solve tasks by reasoning in relative coordinates 
#    anchored to dynamically discovered features?"
#
# If this config works better than RLAN-Full, it proves the core novelty
# and suggests LCR/SPH are not essential.
#
# ==================================
# DEBUGGING CHECKPOINTS (what to look for in training logs)
# ==================================
# 
# EPOCH 5-10 (Early training):
#   - Grad Norms: DSC should be > 0.01 (gradients flowing)
#   - Per-Clue Entropy: Should be < 5.0 (attention starting to focus)
#   - Attention max: Should be > 0.01 (not uniform)
#   - Task Loss: Should be dropping from ~2.4
#
# EPOCH 25 (DSC should be contributing):
#   - Per-Clue Entropy: Should be < 4.0 (focused attention)
#   - Centroid Spread: Should be > 3.0 (clues spreading out)
#   - Per-Step Loss: Later steps should be lower than earlier steps
#   - Non-BG Accuracy: Should be > 0.1 (not just predicting black)
#
# EPOCH 50 (DSC fully engaged):
#   - Per-Clue Entropy: Should be < 3.0 (sharp attention)
#   - Attention max: Should be > 0.1 (very focused)
#   - Task Accuracy: Should be > 0.0 (some tasks solved)
#   - Deep Supervision Loss: Should be > 0.0 (contributing to learning)
#
# RED FLAGS (problems requiring intervention):
#   - DSC grad norm < 0.001 → gradients not reaching DSC
#   - Entropy > 5.0 after epoch 25 → attention still diffuse
#   - Centroid spread < 2.0 → all clues attending to same location
#   - Non-BG Accuracy decreasing → background collapse
#   - Per-Step Loss not improving → solver not refining
# ==================================

model:
  type: "rlan"
  hidden_dim: 256
  num_colors: 10
  num_classes: 10   # colors 0-9 (no boundary markers needed)
  max_grid_size: 30
  
  max_clues: 6
  num_predicates: 8
  num_solver_steps: 6
  
  use_act: true
  dropout: 0.1
  
  dsc_num_heads: 4
  lcr_num_heads: 4
  
  msre_encoding_dim: 32
  msre_num_freq: 8
  lcr_num_freq: 8
  
  # =============================================================
  # ABLATION: Core Novelty Only (DSC + MSRE)
  # =============================================================
  # NOTE: ContextEncoder MUST be enabled - it provides task signal!
  # Without it, the model has NO information about what transformation
  # to learn, causing inevitable background collapse.
  # 
  # The bottleneck concern (4.2M params -> 256-dim) is real but:
  # 1. The context vector conditions DSC's clue discovery
  # 2. Without context, DSC finds random clues
  # 3. Even a compressed signal is better than none
  # =============================================================
  use_context_encoder: true   # ENABLED - REQUIRED for task signal
  use_dsc: true               # ENABLED - CORE NOVELTY
  use_msre: true              # ENABLED - CORE NOVELTY
  use_lcr: false              # DISABLED - auxiliary
  use_sph: false              # DISABLED - auxiliary
  use_learned_pos: false      # Use sinusoidal (default) vs learned absolute positions

training:
  max_epochs: 500
  
  batch_size: 64  # Reduced since ContextEncoder is now enabled
  grad_accumulation_steps: 4
  
  learning_rate: 1.0e-4
  weight_decay: 0.1
  gradient_clip: 5.0  # INCREASED from 2.0 - allow stronger updates for ARC learning
  
  # Temperature schedule for Gumbel-Softmax (DSC attention sharpness)
  # =================================================================
  # GOAL: See DSC contribute meaningfully within first 50 epochs
  # 
  # Temperature controls attention sharpness in Gumbel-Softmax:
  #   temp > 2.0: Nearly uniform attention (99% entropy) - DSC can't learn
  #   temp ~ 1.0: Moderately sharp - DSC starts learning
  #   temp < 0.5: Very sharp - risk of gradient issues
  #
  # Schedule analysis (exponential decay):
  #   tau_start=5.0: reaches 1.0 at epoch 206 (TOO SLOW)
  #   tau_start=2.0: reaches 1.0 at epoch 116 (STILL SLOW)
  #   tau_start=1.0: always below 1.0, sharp from start (FOR DEBUGGING)
  #
  # Using 1.0 for debugging - we need to see DSC working early!
  # =================================================================
  temperature_start: 1.0   # Sharp from start for debugging DSC
  temperature_end: 0.1
  
  # =============================================================
  # LOSS: PURE STABLEMAX (TRM-Proven Approach)
  # =============================================================
  # Following TRM's proven training: pure stablemax with NO weighting
  # Combined with 100% color permutation for natural class balancing
  # If RLAN architecture is superior, it should learn faster
  # =============================================================
  loss_mode: 'stablemax'  # Pure stablemax, no class weighting
  bg_weight_cap: 2.0           # BG weight (ensures ~52% gradient to BG)
  fg_weight_cap: 5.0           # Max FG weight (rarest class = 5.0)
  
  # Focal params
  focal_gamma: 2.0             # Focusing parameter
  focal_alpha: 0.75            # Only used for legacy focal modes
  
  # Auxiliary loss weights
  # =================================================================
  # lambda_entropy: Penalizes high entropy (diffuse attention)
  #   - Higher = stronger pressure for sharp attention
  #   - 0.1 is mild, 0.5 is strong
  #   - Increase if DSC entropy stays high (>4.0) after epoch 25
  #
  # CRITICAL: Higher entropy penalty forces DSC to focus on fewer pixels,
  # which naturally leads to focusing on foreground objects (sparse in ARC)
  #
  # lambda_sparsity: THREE-COMPONENT clue usage penalty:
  #   1. min_clue_penalty: Prevents collapse to 0 clues
  #   2. base_pondering: Cost per clue used (ACT-style)
  #   3. entropy_pondering: Extra cost for diffuse (bad quality) attention
  #
  # CRITICAL INSIGHT: Clue count is a LATENT VARIABLE learned from target grids!
  # - The model learns to use the RIGHT number of clues for each task
  # - Easy tasks (single object) -> 1-2 clues
  # - Complex tasks (multiple objects) -> more clues
  # - No fixed "target" clue count - it emerges from minimizing task_loss
  #
  # How it works:
  # 1. stop_logits weight clue contributions in _aggregate_clues()
  # 2. Gradient flows: task_loss -> logits -> aggregated -> stop_probs -> stop_predictor
  # 3. Model learns per-sample clue counts that minimize prediction error
  #
  # ponder_weight: Base cost per clue used (0.1 = mild, 0.5 = strong)
  #   - Encourages efficiency but doesn't dictate the number
  # entropy_ponder_weight: Extra cost for high-entropy attention
  #   - Sharp attention (low entropy) -> small extra cost -> can use clue cheaply
  #   - Diffuse attention (high entropy) -> large extra cost -> expensive bad clue
  #
  # FIX: Reduced from 0.5/0.3 - too aggressive early, causing clue collapse
  # Let the model learn to use clues FIRST, then add regularization
  # FIX2: Further reduced entropy from 0.1 to 0.01 - was 30% of total loss!
  # =================================================================
  lambda_entropy: 0.01     # REDUCED AGAIN - was dominating task loss
  lambda_sparsity: 0.1     # REDUCED - don't penalize clue usage too early
  
  # =================================================================
  # CLUE COUNT AS LATENT VARIABLE (learned from task loss)
  # =================================================================
  # CRITICAL FIX: Previously, clue_usage was normalized to sum to 1,
  # which killed all gradient signal about HOW MANY clues to use.
  # Now, we aggregate WITHOUT normalizing (divide by constant K),
  # so the output magnitude varies with clue count, giving the solver
  # direct signal about clue count.
  #
  # With this fix:
  # - Task loss gradient flows to stop_probs based on clue usefulness
  # - Easy tasks naturally learn to use fewer clues (e.g., 1-2)
  # - Hard tasks naturally learn to use more clues (e.g., 4-5)
  # - No artificial min_clues needed!
  #
  # Regularization provides mild efficiency pressure:
  # - ponder_weight: small cost per clue (encourages parsimony)
  # - entropy_ponder_weight: cost for diffuse attention (quality control)
  #
  # =================================================================
  # CLUE USAGE REGULARIZATION
  # =================================================================
  # The model was collapsing to 0 clues (stop_prob=0.996) because
  # there was no penalty for not using clues. Re-enable min_clue penalty.
  #
  # min_clues: Minimum expected clues (soft target)
  # min_clue_weight: Strength of penalty for using fewer clues
  #
  # With per-sample gradient coupling, the model learns per-task clue counts.
  # min_clues=1 allows simple tasks to use 1 clue while complex tasks use more.
  # The per-sample penalty ensures each task gets appropriate pressure.
  # =================================================================
  min_clues: 1.0           # Allow simple tasks to use just 1 clue
  min_clue_weight: 1.0     # Moderate penalty for using fewer than min
  ponder_weight: 0.0       # No cost per clue (let model use as many as needed)
  entropy_ponder_weight: 0.0  # No extra cost for diffuse attention
  lambda_predicate: 0.0    # Disabled - no SPH in this ablation
  lambda_curriculum: 0.0
  lambda_deep_supervision: 0.5  # Stronger intermediate supervision
  lambda_act: 0.0          # DISABLED - was contributing 41% of loss, conflicting with task learning
  
  use_stablemax: true
  
  use_curriculum: false
  curriculum_stages: []
  
  optimizer: "adamw"
  beta1: 0.9
  beta2: 0.95
  scheduler: "onecycle"
  warmup_epochs: 20
  min_lr: 1.0e-6
  
  use_ema: true
  # FIX: Reduced from 0.999 to 0.995 to prevent EMA lag
  # At 0.999, EMA trails ~1000 steps behind training model
  # At 0.995, EMA trails ~200 steps - better for eval accuracy
  ema_decay: 0.995

data:
  train_path: "./data/arc-agi/data/training"
  eval_path: "./data/arc-agi/data/evaluation"
  
  max_grid_size: 30
  
  num_workers: 24
  pin_memory: true
  prefetch_factor: 4
  persistent_workers: true
  
  cache_samples: false
  
  augmentation:
    enabled: true
    rotation: true
    flip: true
    transpose: true
    color_permutation: true
    color_permutation_prob: 1.0  # TRM-style: 100% color permutation for class balancing
    translational: true

evaluation:
  num_guesses: 2
  use_tta: true
  tta_rotations: [0, 90, 180, 270]
  tta_flips: [false, true]

logging:
  log_every: 1
  save_every: 25
  eval_every: 5
  keep_last_n: 5
  checkpoint_dir: "checkpoints/rlan_core_ablation"
  log_to_file: true
  track_augmentation: true
  
  use_wandb: false
  wandb_project: "rlan-arc"
  wandb_run_name: null

hardware:
  device: "cuda"
  seed: 42
  deterministic: false

device:
  use_cuda: true
  mixed_precision: true
  dtype: "bfloat16"
  compile: false
