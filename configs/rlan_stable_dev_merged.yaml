# RLAN STABLE DEV MERGED Configuration
# =====================================
# Configuration for training on MERGED dataset (ARC-AGI-1 + ARC-AGI-2)
# Based on rlan_stable_dev.yaml with merged training enabled.
#
# USAGE:
# 1. Build merged dataset: python scripts/build_merged_training_set.py
# 2. Train with: python scripts/train_rlan.py configs/rlan_stable_dev_merged.yaml --resume checkpoints/rlan_stable_dev/latest.pt --reset-optimizer
#
# KEY CHANGES FROM rlan_stable_dev.yaml:
# - use_merged_training: true (was false)
# - cache_path: Updated for merged dataset
# - num_cached_samples: auto (computed for 602 tasks)
#
# WARM START WORKFLOW (Jan 2026):
# This config is designed for continuing training from epoch 30 checkpoint
# using the --reset-optimizer flag to start fresh on merged data.
#
# HARDWARE TARGET: RTX 3090 (24GB VRAM), 48 virtual CPUs, 128GB RAM
#
# VALIDATION CHECKLIST (Jan 2026 Patch):
# ☐ Verify merged manifest exists: data/merged_training/merged_train_manifest.jsonl
# ☐ At train start, check logs for "TASK ID VALIDATION" section
# ☐ Expected: ~602 unique task IDs (AGI-1 400 + AGI-2 202)
# ☐ If unique IDs << 602, check for task_id collisions in manifest
# ☐ Canonical train eval should show stable metrics epoch-to-epoch
#
# ==========================

model:
  type: "rlan"
  hidden_dim: 256
  num_colors: 10
  num_classes: 10  # colors 0-9
  max_grid_size: 30
  
  max_clues: 7
  num_predicates: 32  # More predicates for diversity
  num_solver_steps: 7   # Increased from 5 for more iteration capacity (user request Jan 2026)
  
  use_act: false       # DISABLED
  dropout: 0.1
  
  # =============================================================
  # BEST-STEP SELECTION (Dec 2025)
  # =============================================================
  # ENABLED (Jan 2026 Patch): Aligns inference with training by selecting
  # the solver step with lowest entropy (most confident prediction).
  # This improves exact match by allowing the model to "stop early" when
  # it has the right answer rather than always using the last step.
  # =============================================================
  use_best_step_selection: true
  
  dsc_num_heads: 4
  dsc_use_complexity_signals: true  # Jan 2026: Task-aware stop prediction
  lcr_num_heads: 4     # Not used
  
  msre_encoding_dim: 32
  msre_num_freq: 8
  lcr_num_freq: 8      # Not used
  
  # CORE MODULES ONLY (ablation validated)
  use_context_encoder: true   # REQUIRED - learns task from demos
  use_dsc: true               # REQUIRED - dynamic spatial cluing
  use_msre: true              # REQUIRED - multi-scale relative encoding
  use_lcr: false              # DISABLED - not needed for learning
  
  # Context injection mode
  use_cross_attention_context: true
  spatial_downsample: 8       # 8x8 target - preserves objects while being memory-efficient
  use_sph: false              # DISABLED - not needed for learning
  use_learned_pos: false      # DISABLED - sinusoidal works better
  
  # Solver Cross-Attention to Support Set
  use_solver_context: true    # ENABLED - critical for iterative verification
  solver_context_heads: 4     # Multi-head attention for diverse queries
  
  # =============================================================
  # HYPER-LORA: META-LEARNING WEIGHT ADAPTATION
  # =============================================================
  use_hyperlora: false       # DISABLED for program-guided training focus
  hyperlora_rank: 8          # LoRA rank (lower = fewer params, less expressive)
  hyperlora_scaling: 1.0     # Scale factor for LoRA outputs
  hyperlora_dropout: 0.0     # Dropout on LoRA activations
  hyperlora_init_scale: 0.005  # NEAR-ZERO: Start as identity, warmup to 0.1 (was 0.1)
  hyperlora_max_norm: 1.0    # STABILITY FIX: Clamp LoRA delta L2 norm (prevents collapse)

  # =============================================================
  # HIERARCHICAL PRIMITIVE MEMORY (HPM v2)
  # =============================================================
  use_hpm: false                      # DISABLED for program-guided training focus
  hpm_start_epoch: 20                 # Activate HPM at epoch 20 (after equivariance @ 16, before LOO @ 24)
  
  # Sparse MoE Routing Configuration
  hpm_top_k: 2                        # Number of banks to route to per sample
  hpm_balance_weight: 0.01            # Load balancing loss weight (prevents mode collapse)
  
  # Static Bank Configuration
  hpm_primitives_per_bank: 32         # Number of primitives per static bank (was 16)
  hpm_levels_per_bank: 3              # Hierarchical levels within each bank (was 2)
  hpm_use_cross_attention: true       # Use cross-attention aggregation
  
  # Dynamic Bank Configuration
  hpm_memory_size: 10000              # Max entries in dynamic banks (enough for 10x ARC)
  hpm_retrieval_k: 5                  # Number of neighbors to retrieve
  
  # Bank Selection
  hpm_use_compositional_bank: true    # Transformations that compose
  hpm_use_pattern_bank: true          # Holistic patterns/templates
  hpm_use_relational_bank: true       # Spatial/logical relationships
  hpm_use_concept_bank: false         # Domain knowledge (optional)
  
  # Dynamic banks
  hpm_use_procedural_bank: false      # DISABLED - requires HyperLoRA
  hpm_use_instance_bank: false        # DISABLED - HPM is off
  
  # HPM Buffer Storage
  hpm_buffer_path: "checkpoints/rlan_stable_merged/hpm"  # Merged config path
  hpm_buffer_save_frequency: 1
  hpm_buffer_stale_days: 7
  hpm_buffer_auto_load: true
  
  # HPM Memory Collection
  hpm_memory_start_epoch: 0  # Start collecting solved task memories from epoch 0
  
  # HPM Solver-Context Coupling
  hpm_solver_context_enabled: true
  hpm_solver_context_start_epoch: 80
  hpm_solver_context_gate_init: 0.0
  hpm_solver_context_gate_warmup_epochs: 20
  hpm_solver_context_max_tokens: 4
  hpm_solver_context_gate_max: 0.3
  hpm_solver_context_logit_clamp: 5.0
  hpm_solver_context_disable_on_instability: true

# =============================================================
# PROGRAM-GUIDED TRAINING (Jan 2026)
# =============================================================
# Joint training with NS-TEPS primitive prediction.
# RLAN learns features useful for both pixel prediction AND program discovery.
# At inference, PrimitiveHead provides search guidance to NS-TEPS.
# =============================================================
program_guided:
  enabled: true  # Enable program-guided training with primitive loss
  
  # Primitive Head Architecture
  primitive_head:
    enabled: true
    num_primitives: 17    # Must match NUM_PRIMITIVES in primitive_head.py
    max_objects: 20       # Max objects per grid
    num_params: 8         # Parameter slots per primitive
    param_vocab_size: 32  # Discrete param vocabulary
    hidden_dim: 256       # Match model.hidden_dim
    num_heads: 4
    dropout: 0.1
    
    # Loss weights (relative within primitive loss)
    primitive_loss_weight: 0.5  # Primitive classification
    object_loss_weight: 0.3     # Object selection
    param_loss_weight: 0.2      # Parameter prediction
    
    # Inference settings
    top_k_primitives: 5
    temperature: 1.0
  
  # Loss Configuration
  primitive_loss_weight: 0.3    # Weight relative to pixel loss
  consistency_loss_weight: 0.1  # Program consistency regularization
  
  # Pseudo-label Cache (from NS-TEPS mined programs)
  use_cached_programs: true     # Use pre-computed program cache
  cache_path: "./cache/program_cache_merged_602.json"
  
  # Online mining configuration
  # PROD NOTE: Set online_mining=true initially if cache doesn't exist.
  # After first run, the cache will be populated and you can set to false.
  # With 48 vCPUs, online mining adds ~2s overhead per batch but ensures
  # primitive loss is never skipped due to missing cache entries.
  online_mining: true   # PROD: Enable to build cache during first run
  mining_frequency: 50  # Mine every 50 batches (balance between speed and coverage)
  min_confidence: 0.95
  
  # Curriculum: warmup before primitive loss activates
  warmup_epochs: 3        # Train pixel-only first
  curriculum_epochs: 5    # Ramp up primitive weight over 5 epochs
  
  # NS-TEPS configuration (for online mining or inference)
  # Option B: Extended search for better cache hit-rate (~45-60 min)
  nsteps:
    enabled: true
    max_search_steps: 3000      # Was 500, increased for deeper search
    timeout_seconds: 5.0        # Was 2.0, more time per task
    max_trace_length: 5         # Was 3, allows longer programs
    min_object_size: 1
    max_objects: 20
    sample_count: 200
    match_threshold: 0.95

training:
  max_epochs: 200  # Enough for hard tasks
  
  # Memory optimizations
  use_8bit_optimizer: true    # ~75% optimizer memory savings
  gradient_checkpointing: false  # DISABLED: Known issues
  use_torch_compile: false
  torch_compile_mode: 'reduce-overhead'
  
  # =============================================================
  # BATCH SIZE (Jan 2026 MEMORY FIX)
  # =============================================================
  # =============================================================
  # BATCH SIZE FOR PROGRAM-GUIDED TRAINING (Jan 2026 FIX)
  # Peak at 97.6% with batch=40 → need 30% reduction
  # batch=28 targets ~68% VRAM usage (~17GB peak)
  # Increase grad_accumulation to maintain effective batch size
  # =============================================================
  batch_size: 28    # Reduced for 24GB VRAM safety (was 40)
  grad_accumulation_steps: 13  # Effective batch_size = 28 × 13 = 364
  
  learning_rate: 5.0e-4  # Works well in ablation
  weight_decay: 0.01     # Light regularization
  gradient_clip: 1.0     # Conservative
  
  # Per-module LR boosting
  dsc_lr_multiplier: 1.0
  msre_lr_multiplier: 1.0
  hyperlora_lr_multiplier: 1.0   # CONSERVATIVE: Same as base
  primitive_head_lr_multiplier: 2.0  # PrimitiveHead for program-guided training
  
  # Temperature for DSC attention
  temperature_start: 1.0
  temperature_end: 0.5
  
  # Loss configuration - FOCAL WEIGHTED
  loss_mode: 'focal_weighted'
  bg_weight_cap: 1.0
  fg_weight_cap: 6.0
  
  focal_gamma: 1.2
  focal_alpha: 0.75
  
  # AUXILIARY LOSSES
  lambda_entropy: 0.01
  lambda_sparsity: 0.5
  lambda_predicate: 0.01
  lambda_curriculum: 0.0
  lambda_deep_supervision: 0.0
  lambda_act: 0.0
  lambda_centroid_diversity: 0.3
  
  # Clue regularization
  min_clues: 1.0
  min_clue_weight: 5.0
  ponder_weight: 0.02
  entropy_ponder_weight: 0.02
  
  # Variance regularization
  clue_variance_weight: 1.0
  clue_target_variance: 0.5
  
  # Stop logit saturation guard
  stop_saturation_weight: 0.5
  stop_saturation_threshold: 5.0
  
  use_stablemax: true
  
  use_curriculum: false
  curriculum_stages: []
  
  optimizer: "adamw"
  beta1: 0.9
  beta2: 0.95
  
  # NO SCHEDULER - constant LR (most stable)
  scheduler: "none"
  warmup_epochs: 0
  min_lr: 5.0e-4
  
  # EMA
  use_ema: false
  ema_decay: 0.995
  
  # =============================================================
  # STAGED META-LEARNING
  # =============================================================
  # NOTE FOR WARM START: These epochs are ABSOLUTE, not relative.
  # When resuming from epoch 30, modules already activated will remain active.
  # The training code checks: if current_epoch >= start_epoch, activate module.
  #
  # PHASED TRAINING COORDINATION (Jan 2026):
  # Phase A (epochs 1-10): No meta, no aug - these start epochs are overridden
  # Phase B (epochs 11-20): Geometric aug only - HyperLoRA still disabled by phase
  # Phase C (epochs 21+): Full meta-learning - all modules can activate
  #
  # Even though meta_learning_start_epoch=21, modules won't activate earlier
  # because phased training disable_hyperlora=true overrides until Phase C.
  # =============================================================
  
  # Context path activates in Phase B (after base solver establishes)
  solver_context_start_epoch: 11
  cross_attention_start_epoch: 15
  
  # HyperLoRA activates at Phase C start (after geometric aug exposure)
  # Note: Phase A/B disable_hyperlora=true prevents early activation
  meta_learning_start_epoch: 21
  
  # HyperLoRA warmup (starts when Phase C allows activation)
  hyperlora_warmup_epochs: 8
  hyperlora_warmup_start_scale: 0.005
  hyperlora_warmup_end_scale: 0.05
  
  # LR reduction at activation epochs
  activation_lr_reduction: 0.5
  activation_lr_recovery_epochs: 2
  
  # Gradient explosion backoff
  grad_explosion_threshold: 10.0
  grad_explosion_lr_reduction: 0.5
  grad_explosion_cooldown_epochs: 2
  
  # =============================================================
  # LOO TRAINING: LEAVE-ONE-OUT META-LEARNING LOSS
  # =============================================================
  # DISABLED for program-guided training focus
  # =============================================================
  loo_training:
    enabled: false  # DISABLED for program-guided training
    start_epoch: 25  # After HyperLoRA warmup completes (21 + 4 buffer epochs)
    loss_weight: 0.05
    min_pairs_for_loo: 2
    max_loo_pairs: 4
    batch_reduction_divisor: 2.0
    min_batch_size: 8
    adjust_grad_accumulation: true
  
  # =============================================================
  # EQUIVARIANCE TRAINING
  # =============================================================
  # CRITICAL FOR TTA CONSENSUS AND DIHEDRAL INVARIANCE
  # =============================================================
  equivariance_training:
    # Weight-level equivariance (DEPRECATED - often ~0 due to D4-invariant pooling)
    enabled: false  # Disabled in favor of output-level equivariance
    start_epoch: 21
    loss_weight: 0.01
    num_augmentations: 4

  # =============================================================
  # OUTPUT-LEVEL EQUIVARIANCE (DISABLED for Program-Guided Training)
  # =============================================================
  # DISABLED for program-guided training focus
  # =============================================================
  output_equivariance_training:
    enabled: false  # DISABLED for program-guided training
    start_epoch: 22  # Shortly after Phase C starts (epoch 21)
    loss_weight: 0.02
    num_augmentations: 2  # Keep low - each is a full forward pass
    loss_type: "kl"       # 'kl' or 'l2'
    mask_to_target: true  # Jan 2026: Only compute on valid output region (not padding)

  # =============================================================
  # GROUP-MARGINALIZED NLL (Jan 2026)
  # =============================================================
  # A mathematically principled alternative to output-equiv + regular NLL.
  # Trains directly on the group-marginalized distribution:
  #   p̄(y|x) = (1/K) Σ_g g⁻¹(p(·|g(x)))
  #
  # This directly optimizes what TTA voting tries to achieve, without
  # fighting between NLL and consistency losses.
  #
  # Can be used as:
  #   - AUXILIARY loss (default): adds to regular task loss
  #   - PRIMARY loss: replaces task loss entirely
  # =============================================================
  group_marginalized_nll:
    enabled: false  # Experimental - enable to test
    start_epoch: 22
    loss_weight: 0.1  # As auxiliary loss (lower weight)
    num_augmentations: 2
    as_primary_loss: false  # If true, replaces task loss (use weight=1.0)

  # =============================================================
  # PHASED TRAINING (DISABLED for Program-Guided Training)
  # =============================================================
  # When resuming from warmup checkpoint with --reset-optimizer,
  # we skip phased training since the base solver is already trained.
  # Program-guided training focuses on PrimitiveHead learning.
  # =============================================================
  phased_training:
    enabled: false  # DISABLED for program-guided training
    
    # Phase A: Base solver competence (no meta, limited aug)
    # Goal: Verify base model can learn to solve ARC without help
    phase_a:
      end_epoch: 10
      # Batch size for this phase (Jan 2026 MEMORY FIX)
      # Phase A: No meta modules active → ~18GB peak at batch=50
      # Safe: batch_size=40 → ~15GB peak with headroom
      batch_size: 40
      # Override augmentation for this phase
      augmentation:
        rotation: false
        flip: false
        transpose: false
        color_permutation: false
        translational: false  # Jan 2026: Also disable translational in phase A
      # Disable all meta components
      disable_hyperlora: true
      disable_loo: true
      disable_equivariance: true
      disable_hpm: true
      # Subset training for faster iteration (optional)
      max_tasks: null  # Use all tasks (or set to e.g., 100 for fast validation)
    
    # Phase B: Geometric augmentation + context path
    # Goal: Test equivariance with solver context active
    phase_b:
      start_epoch: 11
      end_epoch: 20
      # Batch size for this phase (Jan 2026 MEMORY FIX)
      # Phase B: solver_context activates → ~25GB peak at batch=50
      # Reduce to batch_size=32 → ~16GB peak with good headroom
      batch_size: 32
      # Enable geometric augmentation
      augmentation:
        rotation: true
        flip: true
        transpose: true
        color_permutation: false  # Still disabled - adds complexity
        translational: true  # Jan 2026: Enable translational in phase B
      # Enable context path only
      disable_hyperlora: true  # HyperLoRA still off
      disable_loo: true
      disable_equivariance: true  # Wait for Phase C
      disable_hpm: true
    
    # Phase C: Full meta-learning
    # Goal: Enable all components after base solver is competent
    phase_c:
      start_epoch: 21
      # Batch size for this phase (Jan 2026 MEMORY FIX)
      # Phase C: All meta modules → HyperLoRA + HPM + LOO → ~30GB peak at batch=50
      # Reduce to batch_size=24 → ~15GB peak with excellent headroom
      # Higher grad_accumulation compensates for effective batch size
      batch_size: 24
      # Full augmentation
      augmentation:
        rotation: true
        flip: true
        transpose: true
        color_permutation: true
        color_permutation_prob: 0.3  # Lower than default for stability
        translational: true  # Jan 2026: Full translational in phase C
      # Enable all meta components (respects their individual start_epochs)
      disable_hyperlora: false
      disable_loo: false
      disable_equivariance: false
      disable_hpm: false

    # =============================================================
    # METRIC-BASED PHASE GATING (Jan 2026)
    # =============================================================
    # Optional: Require metric thresholds IN ADDITION to epoch boundaries.
    # This prevents phase transitions before the model is ready.
    #
    # When use_metric_gating=true:
    #   - At phase boundary epoch, checks if gate criteria are met
    #   - If not met, stays in current phase until criteria pass
    #   - Logs gate status at each evaluation
    #
    # Backward compatible: disabled by default
    #
    # IMPORTANT NOTE ON shape_mismatch (Jan 2026):
    # The TRM eval set has 54/100 tasks where train output shape != test output shape.
    # This is a DATASET PROPERTY (size-transform tasks), NOT a model failure.
    # Setting shape_mismatch_max < 0.54 would block phase transitions forever.
    # Set to 1.0 to disable this check and rely on model-dependent metrics.
    # =============================================================
    phase_readiness:
      use_metric_gating: true  # Enable metric-based gating (false = epoch-only)
      
      # A→B Gate: Base solver must show learning before adding augmentation
      gate_a_to_b:
        min_epochs_in_phase_a: 10       # At least 10 epochs before checking gate
        shape_mismatch_max: 1.0         # DISABLED: 54/100 eval tasks have shape mismatch (dataset property)
        fg_accuracy_min: 0.35           # Eval FG accuracy ≥ 35% (lowered - early phase)
        patience: 2                     # Consecutive evals meeting criteria
        # Optional: Stability requirements
        centroid_collapse_free_epochs: 0  # 0 = disabled; N = no collapse for N epochs
        grad_explosion_free_epochs: 0     # 0 = disabled; N = no explosions for N epochs
        
      # B→C Gate: Solver + augmentation must show improvement before meta-learning
      gate_b_to_c:
        min_epochs_in_phase_b: 5        # At least 5 epochs in Phase B
        shape_mismatch_max: 1.0         # DISABLED: Dataset property, not model metric
        fg_accuracy_min: 0.45           # FG accuracy ≥ 45% (reasonable for Phase B exit)
        tta_exact_match_min: 0.0        # DISABLED: Exact match is rare early; use fg_accuracy instead
        patience: 2                     # Consecutive evals meeting criteria
        vote_tie_max: 0.50              # Vote ties ≤ 50% (relaxed - consensus improves in Phase C)

  # =============================================================
  # META ESCALATION (DISABLED for Program-Guided Training)
  # =============================================================
  meta_escalation:
    enabled: false  # DISABLED for program-guided training
    
    # Meta Loss Capping
    meta_loss_cap_ratio: 0.25
    meta_loss_cap_enabled: true
    
    start_epoch: 25
    ramp_epochs: 12
    schedule: linear
    
    targets:
      hyperlora_delta_scale: 0.20
      equiv_loss_weight: 0.03
      loo_loss_weight: 0.08
    
    require_stability: true
    
    max_grad_explosion_events_per_epoch: 2
    max_lr_backoff_events_per_epoch: 2
    max_consecutive_nan_streak_per_epoch: 3
    
    recovery_enabled: true
    recovery_step_per_window: 0.05
    
    log_every_epoch: true
    
    late_phase:
      enabled: true
      start_epoch: 50
      
      max_grad_explosion_events: 0
      max_lr_backoff_events: 0
      max_attention_collapse_events: 0
      
      decay_targets: false
      target_decay_factor: 0.8
      
      lr_decay:
        enabled: true
        start_epoch: 50
        end_epoch: 200
        decay_factor: 0.1
        schedule: cosine

data:
  train_path: "./data/arc-agi/data/training"
  eval_path: "./data/arc-agi/data/evaluation"
  
  max_grid_size: 30
  
  # CRITICAL: Ignore padding in loss
  ignore_padding_in_loss: true
  
  # ==========================================================================
  # MERGED TRAINING SET (ARC-AGI-1 + ARC-AGI-2) - ENABLED
  # ==========================================================================
  # Uses the merged training set providing ~602 tasks (vs 400 original)
  # for better rule diversity and generalization.
  #
  # REQUIREMENTS:
  # 1. Run: python scripts/build_merged_training_set.py
  # 2. This creates merged_train_manifest.jsonl and merged_dev_manifest.jsonl
  # ==========================================================================
  use_merged_training: true   # ENABLED for merged training
  merged_training_path: "./data/merged_training"
  merged_dev_path: "./data/merged_training"
  merged_manifest_validation: true
  
  # ==========================================================================
  # DATA SAMPLING CONFIGURATION
  # ==========================================================================
  max_tasks: null  # ALL tasks for better generalization
  samples_per_task: 50  # 50 samples per task
  stratified_seed: 42
  
  # Data loading
  # OPTIMIZED for 48 vCPU system (Jan 2026):
  # - num_workers=24 (half of vCPUs, leaves room for main process)
  # - prefetch_factor=4 (more conservative to avoid memory pressure)
  # - persistent_workers=true (avoids worker respawn overhead)
  num_workers: 24
  pin_memory: true
  prefetch_factor: 4
  persistent_workers: true
  
  # ==========================================================================
  # CACHING CONFIGURATION (Jan 2026 PROD FIX)
  # ==========================================================================
  # PROD REASONING for 24GB VRAM / 128GB RAM / 48 vCPU:
  # - cache_samples: true with rolling cache gives BOTH diversity AND enough steps/epoch
  # - 602 tasks × 50 samples = 30,100 samples → ~750 steps/epoch at batch=40
  # - Rolling cache refreshes 25% each epoch → fresh augmentations while training
  # - Without caching: only 602 samples/epoch = ~15 steps → too few for convergence
  #
  # IMPORTANT: Rolling cache mode automatically applies augmentation overrides,
  # so phased augmentation DOES work with rolling cache (unlike static cache).
  # ==========================================================================
  cache_samples: true  # PROD: Enable for sufficient steps/epoch
  cache_samples_mode: rolling  # PROD: Rolling refresh for augmentation diversity
  
  # ==========================================================================
  # CACHE CONFIGURATION FOR MERGED DATASET
  # ==========================================================================
  # These settings are used when cache_samples: true
  # Formula: num_cached_samples = 602 tasks × 50 = 30,100
  # ==========================================================================
  num_cached_samples: auto  # Computed as task_count × samples_per_task
  
  # UPDATED PATH for merged dataset
  cache_path: "./cache/rlan_stable_merged_602tasks.pkl"
  
  # ==========================================================================
  # ROLLING CACHE CONFIGURATION (PROD: 128GB RAM allows large pool)
  # ==========================================================================
  # Rolling cache provides fresh augmentations each epoch while maintaining
  # enough samples for meaningful gradient updates.
  # ==========================================================================
  rolling_cache:
    pool_size: 60000           # 60k samples (~100 per task) - fits in 128GB RAM
    refresh_fraction: 0.25     # Refresh 25% each epoch (15k new samples)
    anti_repeat_window: 4      # Don't repeat same sample for 4 epochs
    prefetch_workers: 8        # Async prefetch with 8 workers (of 48 vCPUs)
    coverage_scheduling: true  # Ensure all tasks represented each epoch
    force_augmentation: true   # Always apply augmentation in rolling cache
  
  cache_load_percent: 100
  
  # Bucketed batching
  bucketed_batching: true
  bucket_boundaries: [10, 15, 20, 25]
  # CRITICAL FIX (Jan 2026): drop_last=true permanently excludes tasks in small buckets!
  # With batch_size=50 and bucket sizes [178, 88, 76, 28, 30], buckets with 28 and 30
  # samples produce ZERO full batches → those 58 tasks are NEVER trained.
  # Setting drop_last=false ensures ALL tasks are trained (incomplete batches are OK).
  drop_last: false
  
  augmentation:
    enabled: true
    rotation: true
    flip: true
    transpose: true
    color_permutation: true
    color_permutation_prob: 0.5
    translational: true
    track_augmentation: true

# =============================================================
# EVALUATION
# =============================================================
evaluation:
  num_guesses: 2
  use_tta: true
  tta_rotations: [0, 90, 180, 270]
  tta_flips: [false, true]
  
  # TRM-style evaluation settings
  use_trm_style_eval: true
  num_augmented_views: 8
  num_color_perms: 4
  use_voting: true
  use_inverse_aug: true
  pass_ks: [1, 2, 3]
  max_eval_tasks: 100
  
  # =============================================================
  # CANONICAL TRAIN EVAL (Jan 2026 Patch)
  # =============================================================
  # Provides a deterministic train accuracy by evaluating on canonical
  # (non-augmented) samples. Useful for detecting true plateaus vs
  # augmentation noise. Independent of random augmentation.
  # =============================================================
  canonical_train_eval:
    enabled: true
    max_tasks: 100  # Limit for speed

# =============================================================
# MONITORING
# =============================================================
monitoring:
  enabled: true
  exact_match_warning: 0.10
  exact_match_critical: 0.20
  entropy_ratio_warning: 2.0
  entropy_ratio_critical: 5.0
  stop_value_warning: 0.15
  stop_value_critical: 0.25
  
  lora_norm_warn: 2.0
  lora_norm_critical: 5.0
  lora_norm_kill: 10.0
  
  nan_batches_abort: 20
  
  tta_consensus_warning: 0.25
  tta_consensus_critical: 0.15
  
  centroid_spread_warning: 2.0
  centroid_spread_critical: 0.5
  
  attn_max_collapse_threshold: 0.02
  attention_collapse_consecutive_threshold: 2
  
  collapse_backoff:
    enabled: true
    cooldown_epochs: 3
    delta_scale_factor: 0.5
    lr_factor: 0.5
    restore_rate: 0.2

logging:
  log_every: 1
  save_every: 10
  eval_every: 10
  keep_last_n: 3
  checkpoint_dir: "checkpoints/rlan_stable_merged"  # NEW checkpoint dir for merged training
  log_to_file: true
  track_augmentation: true
  memory_debug_batches: 5
  
  use_wandb: false
  wandb_project: "rlan-arc"
  wandb_run_name: null

# =============================================================
# INFERENCE SETTINGS
# =============================================================
inference:
  temperature: 0.1
  use_best_step_selection: false
  num_steps_override: null
  
  use_tta: true
  num_dihedral: 8
  num_color_perms: 4
  
  batch_size: 32
  
  loo_sanity_check: true
  loo_threshold: 0.9
  
  acw_enabled: true
  acw_num_views: 8

  meta_learning:
    hyperlora:
      enable: true
      require_trained: true
      fallback_on_failure: true
    
    hpm:
      enable: true
      require_nonempty_buffers: true
      min_buffer_entries: 1
      use_static_banks: true
      use_dynamic_banks: true
    
    solver_context:
      enable: true
    
    cross_attention:
      enable: true

hardware:
  device: "cuda"
  seed: 42
  deterministic: false
  check_nan_inf: true

device:
  use_cuda: true
  mixed_precision: true
  dtype: "bfloat16"
  compile: false
